


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

d1 = pd.read_csv("d1_trabalhado.csv", sep=",")


X = d1.drop(['G3'], axis=1)
y = d1['G3']





from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)


regressor = LinearRegression()
regressor.fit(X_train, y_train)


y_pred = regressor.predict(X_test)





mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)


print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')





selected_features = ['G2','famrel','studytime', 'health']


X = d1[selected_features]
y = d1['G3']


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

regressor = LinearRegression()
regressor.fit(X_train, y_train)

y_pred = regressor.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print(f'Mean Squared Error: {mse}')
print(f'R^2 Score: {r2}')





from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

X = d1[selected_features]
y = d1['G3']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

poly = PolynomialFeatures(degree=2)
X_poly_train = poly.fit_transform(X_train)
X_poly_test = poly.transform(X_test)

model = LinearRegression()
model.fit(X_poly_train, y_train)

y_pred = model.predict(X_poly_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error: %.2f" % mse)
print("R^2 Score: %.2f" % r2)





from sklearn.linear_model import Lasso

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lasso = Lasso(alpha=0.1)

lasso.fit(X_train, y_train)
y_pred = lasso.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error: %.2f" % mse)
print("R^2 Score: %.2f" % r2)

print("Coeficientes:", lasso.coef_)


feature_names = d1.columns[:-1] 

sorted_indices = np.argsort(np.abs(lasso.coef_))[::-1]
sorted_coefs = lasso.coef_[sorted_indices]
sorted_feature_names = feature_names[sorted_indices]

plt.figure(figsize=(12, 8))
plt.barh(range(len(sorted_coefs)), sorted_coefs, align='center')
plt.yticks(range(len(sorted_coefs)), sorted_feature_names)
plt.xlabel('Coeficientes')
plt.title('Importância das Variáveis - Lasso Regression')
plt.grid(True)
plt.show()





from sklearn.tree import DecisionTreeRegressor
from sklearn.metrics import mean_squared_error, r2_score

selected_features = ['absences', 'G2', 'studytime', 'failures']
X = d1[selected_features]
y = d1['G3']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

decision_tree = DecisionTreeRegressor(random_state=42)

decision_tree.fit(X_train, y_train)
y_pred = decision_tree.predict(X_test)

mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error: %.2f" % mse)
print("R^2 Score: %.2f" % r2)



